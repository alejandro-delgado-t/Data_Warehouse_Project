{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Data Managment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas tools\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import io\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Database-related tools\n",
    "import duckdb\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Other utilities\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to the databases (including the data warehouse) and the .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection or extraction to the provided data sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to the AIMS and AMOS databases\n",
    "if 'aims' in globals():\n",
    "  aims.close()\n",
    "aims = psycopg2.connect(database='aims', user='bse_airlines', host='dtim.essi.upc.edu', password='BSE2024!', options='-c search_path=bda-aims')\n",
    "if 'amos' in globals():\n",
    "  amos.close()\n",
    "amos = psycopg2.connect(database='amos', user='bse_airlines', host='dtim.essi.upc.edu', password='BSE2024!', options='-c search_path=bda-amos')\n",
    "\n",
    "# Reading the .csv (must ensure that it is in the same working directory as this notebook)\n",
    "dfAircrafts = pd.read_csv('aircraft-manufaturerinfo-lookup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the data warehouse (ROLAP) using the SQL scripts in the `tables_dw` folder. Note that the code below creates a new database for the specified user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'lab3_dw_delgado_fernandez' dropped successfully (if it existed).\n",
      "Database 'lab3_dw_delgado_fernandez' created successfully.\n",
      "Dropped all existing tables.\n",
      "Executed SQL file: tables_dw\\01_Route.sql\n",
      "Executed SQL file: tables_dw\\02_Aircraft.sql\n",
      "Executed SQL file: tables_dw\\03_Flights.sql\n",
      "Executed SQL file: tables_dw\\04_Scheduled_routes.sql\n",
      "Executed SQL file: tables_dw\\05_Flight_Issues.sql\n",
      "Executed SQL file: tables_dw\\06_Maintenance_time.sql\n",
      "Executed SQL file: tables_dw\\07_ADOS.sql\n"
     ]
    }
   ],
   "source": [
    "# Database connection parameters\n",
    "DB_NAME = \"lab3_dw_delgado_fernandez\"\n",
    "DB_USER = \"postgres\"    # Adjust as necessary\n",
    "DB_PASSWORD = \"datamanagement\"    # Adjust as necessary\n",
    "DB_HOST = \"localhost\"    # Adjust as necessary\n",
    "DB_PORT = \"5432\"    # Adjust as necessary\n",
    "\n",
    "# PostgreSQL default connection (to 'postgres' database)\n",
    "DEFAULT_DB_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/postgres\"\n",
    "\n",
    "# Function to drop and recreate the database\n",
    "def recreate_database():\n",
    "    try:\n",
    "        # Connect to the default 'postgres' database\n",
    "        connection = psycopg2.connect(\n",
    "            dbname=\"postgres\", \n",
    "            user=DB_USER, \n",
    "            password=DB_PASSWORD, \n",
    "            host=DB_HOST, \n",
    "            port=DB_PORT\n",
    "        )\n",
    "        connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Drop the database if it exists\n",
    "        cursor.execute(f\"SELECT pg_terminate_backend(pg_stat_activity.pid) \"\n",
    "                       f\"FROM pg_stat_activity WHERE pg_stat_activity.datname = '{DB_NAME}';\")\n",
    "        cursor.execute(f\"DROP DATABASE IF EXISTS {DB_NAME};\")\n",
    "        print(f\"Database '{DB_NAME}' dropped successfully (if it existed).\")\n",
    "\n",
    "        # Create the new database\n",
    "        cursor.execute(f\"CREATE DATABASE {DB_NAME};\")\n",
    "        print(f\"Database '{DB_NAME}' created successfully.\")\n",
    "\n",
    "        # Close the connection\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error recreating database: {e}\")\n",
    "\n",
    "# Function to execute an SQL file\n",
    "def execute_sql_file(file_path, engine):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sql_code = file.read()\n",
    "        with engine.connect() as connection:\n",
    "            try:\n",
    "                connection.execute(text(sql_code))\n",
    "                connection.commit()  # Commit the transaction\n",
    "                print(f\"Executed SQL file: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing {file_path}: {e}\")\n",
    "\n",
    "# Function to drop all tables in the database\n",
    "def drop_all_tables(engine):\n",
    "    inspector = inspect(engine)\n",
    "    with engine.connect() as connection:\n",
    "        transaction = connection.begin()\n",
    "        try:\n",
    "            for table_name in inspector.get_table_names():\n",
    "                connection.execute(text(f\"DROP TABLE IF EXISTS {table_name} CASCADE\"))\n",
    "            transaction.commit()\n",
    "            print(\"Dropped all existing tables.\")\n",
    "        except Exception as e:\n",
    "            transaction.rollback()\n",
    "            print(f\"Error dropping tables: {e}\")\n",
    "\n",
    "# Function to create tables\n",
    "def create_tables(engine):\n",
    "    directory = 'tables_dw'  # Directory containing SQL files\n",
    "    files_path = sorted([os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.sql')])\n",
    "\n",
    "    for file_path in files_path:\n",
    "        execute_sql_file(file_path, engine)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Recreate the database (i.e., drop preexisting DB with the same name \n",
    "    # and create a new one)\n",
    "    recreate_database()\n",
    "\n",
    "    # Step 2: Connect to the newly created database\n",
    "    DATABASE_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "\n",
    "    # Step 3: Drop all tables and create new ones\n",
    "    drop_all_tables(engine)\n",
    "    create_tables(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to connect to this database through DBeaver after it has been created by creating a new PostgreSQL connection and specifying the adequate fields *name*, *user*, *password*, *host* and *port*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to the data warehouse\n",
    "outputDB = duckdb.connect(database=':memory:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQiwbpSQVeVZ"
   },
   "source": [
    "## Extracting the AIMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkhOoK7Ernfi",
    "outputId": "1c1dfae6-9706-48b1-b770-150d91323f13"
   },
   "outputs": [],
   "source": [
    "# SQL query\n",
    "query_flights_aims = \"SELECT * FROM Flights;\"\n",
    "\n",
    "# Creating a cursor and executing the query\n",
    "cursor = aims.cursor()\n",
    "cursor.execute(query_flights_aims)\n",
    "\n",
    "# Fetch all rows from the result\n",
    "flights_aims = cursor.fetchall()\n",
    "\n",
    "# Extract column names from cursor.description\n",
    "column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Close the cursor\n",
    "cursor.close()\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df_flights = pd.DataFrame(flights_aims, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>aircraftregistration</th>\n",
       "      <th>scheduleddeparture</th>\n",
       "      <th>scheduledarrival</th>\n",
       "      <th>kind</th>\n",
       "      <th>flightid</th>\n",
       "      <th>departureairport</th>\n",
       "      <th>arrivalairport</th>\n",
       "      <th>actualdeparture</th>\n",
       "      <th>actualarrival</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>delaycode</th>\n",
       "      <th>passengers</th>\n",
       "      <th>cabincrew</th>\n",
       "      <th>flightcrew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>XY-RJL</td>\n",
       "      <td>2023-08-03 11:03:03.875940</td>\n",
       "      <td>2023-08-03 14:03:03.875940</td>\n",
       "      <td>Flight</td>\n",
       "      <td>230803-NRN-JMK-9129-XY-RJL</td>\n",
       "      <td>NRN</td>\n",
       "      <td>JMK</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>XY-OZE</td>\n",
       "      <td>2023-07-26 14:50:15.569812</td>\n",
       "      <td>2023-07-26 15:50:15.569812</td>\n",
       "      <td>Flight</td>\n",
       "      <td>230726-HAU-SAW-9867-XY-OZE</td>\n",
       "      <td>HAU</td>\n",
       "      <td>SAW</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>XY-SJZ</td>\n",
       "      <td>2023-11-20 09:01:04.308766</td>\n",
       "      <td>2023-11-20 13:01:04.308766</td>\n",
       "      <td>Flight</td>\n",
       "      <td>231120-HER-VAA-6975-XY-SJZ</td>\n",
       "      <td>HER</td>\n",
       "      <td>VAA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>137</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>XY-OXK</td>\n",
       "      <td>2023-06-13 09:55:02.480695</td>\n",
       "      <td>2023-06-13 11:55:02.480695</td>\n",
       "      <td>Flight</td>\n",
       "      <td>230613-VNO-EGC-9468-XY-OXK</td>\n",
       "      <td>VNO</td>\n",
       "      <td>EGC</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>XY-DGU</td>\n",
       "      <td>2023-03-12 00:41:45.198279</td>\n",
       "      <td>2023-03-12 03:41:45.198279</td>\n",
       "      <td>Flight</td>\n",
       "      <td>230312-BLL-BVA-9815-XY-DGU</td>\n",
       "      <td>BLL</td>\n",
       "      <td>BVA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>174</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151828</th>\n",
       "      <td>151829</td>\n",
       "      <td>XY-ZZE</td>\n",
       "      <td>2023-12-26 15:17:52.027524</td>\n",
       "      <td>2023-12-26 16:17:52.027524</td>\n",
       "      <td>Flight</td>\n",
       "      <td>231226-NUE-MAH-9264-XY-ZZE</td>\n",
       "      <td>NUE</td>\n",
       "      <td>MAH</td>\n",
       "      <td>2023-12-26 15:26:52.027524</td>\n",
       "      <td>2023-12-26 16:26:52.027524</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151829</th>\n",
       "      <td>151830</td>\n",
       "      <td>XY-ZZE</td>\n",
       "      <td>2023-12-27 00:01:09.300599</td>\n",
       "      <td>2023-12-27 05:01:09.300599</td>\n",
       "      <td>Flight</td>\n",
       "      <td>231227-PAD-BIQ-9447-XY-ZZE</td>\n",
       "      <td>PAD</td>\n",
       "      <td>BIQ</td>\n",
       "      <td>2023-12-27 00:05:09.300599</td>\n",
       "      <td>2023-12-27 05:05:09.300599</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151830</th>\n",
       "      <td>151831</td>\n",
       "      <td>XY-ZZE</td>\n",
       "      <td>2023-12-27 18:55:33.495694</td>\n",
       "      <td>2023-12-27 19:55:33.495694</td>\n",
       "      <td>Flight</td>\n",
       "      <td>231227-SUF-MAD-1652-XY-ZZE</td>\n",
       "      <td>SUF</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2023-12-27 19:02:33.495694</td>\n",
       "      <td>2023-12-27 20:02:33.495694</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>175</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151831</th>\n",
       "      <td>151832</td>\n",
       "      <td>XY-ZZE</td>\n",
       "      <td>2023-12-28 00:09:38.859140</td>\n",
       "      <td>2023-12-28 04:09:38.859140</td>\n",
       "      <td>Flight</td>\n",
       "      <td>231228-AAL-INN-7485-XY-ZZE</td>\n",
       "      <td>AAL</td>\n",
       "      <td>INN</td>\n",
       "      <td>2023-12-28 00:22:38.859140</td>\n",
       "      <td>2023-12-28 04:22:38.859140</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151832</th>\n",
       "      <td>151833</td>\n",
       "      <td>XY-ZZE</td>\n",
       "      <td>2023-12-28 18:47:01.132533</td>\n",
       "      <td>2023-12-28 19:47:01.132533</td>\n",
       "      <td>Flight</td>\n",
       "      <td>231228-TGD-SUF-2356-XY-ZZE</td>\n",
       "      <td>TGD</td>\n",
       "      <td>SUF</td>\n",
       "      <td>2023-12-28 18:49:01.132533</td>\n",
       "      <td>2023-12-28 19:49:01.132533</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>153</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151833 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id aircraftregistration         scheduleddeparture  \\\n",
       "0            1               XY-RJL 2023-08-03 11:03:03.875940   \n",
       "1            2               XY-OZE 2023-07-26 14:50:15.569812   \n",
       "2            3               XY-SJZ 2023-11-20 09:01:04.308766   \n",
       "3            4               XY-OXK 2023-06-13 09:55:02.480695   \n",
       "4            5               XY-DGU 2023-03-12 00:41:45.198279   \n",
       "...        ...                  ...                        ...   \n",
       "151828  151829               XY-ZZE 2023-12-26 15:17:52.027524   \n",
       "151829  151830               XY-ZZE 2023-12-27 00:01:09.300599   \n",
       "151830  151831               XY-ZZE 2023-12-27 18:55:33.495694   \n",
       "151831  151832               XY-ZZE 2023-12-28 00:09:38.859140   \n",
       "151832  151833               XY-ZZE 2023-12-28 18:47:01.132533   \n",
       "\n",
       "                 scheduledarrival             kind  \\\n",
       "0      2023-08-03 14:03:03.875940  Flight            \n",
       "1      2023-07-26 15:50:15.569812  Flight            \n",
       "2      2023-11-20 13:01:04.308766  Flight            \n",
       "3      2023-06-13 11:55:02.480695  Flight            \n",
       "4      2023-03-12 03:41:45.198279  Flight            \n",
       "...                           ...              ...   \n",
       "151828 2023-12-26 16:17:52.027524  Flight            \n",
       "151829 2023-12-27 05:01:09.300599  Flight            \n",
       "151830 2023-12-27 19:55:33.495694  Flight            \n",
       "151831 2023-12-28 04:09:38.859140  Flight            \n",
       "151832 2023-12-28 19:47:01.132533  Flight            \n",
       "\n",
       "                          flightid departureairport arrivalairport  \\\n",
       "0       230803-NRN-JMK-9129-XY-RJL              NRN            JMK   \n",
       "1       230726-HAU-SAW-9867-XY-OZE              HAU            SAW   \n",
       "2       231120-HER-VAA-6975-XY-SJZ              HER            VAA   \n",
       "3       230613-VNO-EGC-9468-XY-OXK              VNO            EGC   \n",
       "4       230312-BLL-BVA-9815-XY-DGU              BLL            BVA   \n",
       "...                            ...              ...            ...   \n",
       "151828  231226-NUE-MAH-9264-XY-ZZE              NUE            MAH   \n",
       "151829  231227-PAD-BIQ-9447-XY-ZZE              PAD            BIQ   \n",
       "151830  231227-SUF-MAD-1652-XY-ZZE              SUF            MAD   \n",
       "151831  231228-AAL-INN-7485-XY-ZZE              AAL            INN   \n",
       "151832  231228-TGD-SUF-2356-XY-ZZE              TGD            SUF   \n",
       "\n",
       "                  actualdeparture              actualarrival  cancelled  \\\n",
       "0                             NaT                        NaT       True   \n",
       "1                             NaT                        NaT       True   \n",
       "2                             NaT                        NaT       True   \n",
       "3                             NaT                        NaT       True   \n",
       "4                             NaT                        NaT       True   \n",
       "...                           ...                        ...        ...   \n",
       "151828 2023-12-26 15:26:52.027524 2023-12-26 16:26:52.027524      False   \n",
       "151829 2023-12-27 00:05:09.300599 2023-12-27 05:05:09.300599      False   \n",
       "151830 2023-12-27 19:02:33.495694 2023-12-27 20:02:33.495694      False   \n",
       "151831 2023-12-28 00:22:38.859140 2023-12-28 04:22:38.859140      False   \n",
       "151832 2023-12-28 18:49:01.132533 2023-12-28 19:49:01.132533      False   \n",
       "\n",
       "       delaycode  passengers  cabincrew  flightcrew  \n",
       "0           None          98          3           2  \n",
       "1           None         107          4           3  \n",
       "2           None         137          3           2  \n",
       "3           None         102          4           2  \n",
       "4           None         174          4           2  \n",
       "...          ...         ...        ...         ...  \n",
       "151828      None          96          4           3  \n",
       "151829      None         112          4           3  \n",
       "151830      None         175          4           2  \n",
       "151831      None         128          3           3  \n",
       "151832      None         153          4           2  \n",
       "\n",
       "[151833 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query\n",
    "query_slots_aims = \"SELECT * FROM Slots;\"\n",
    "\n",
    "# Creating a cursor and executing the query\n",
    "cursor = aims.cursor()\n",
    "cursor.execute(query_slots_aims)\n",
    "\n",
    "# Fetch all rows from the result\n",
    "slots_aims = cursor.fetchall()\n",
    "\n",
    "# Extract column names from cursor.description\n",
    "column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Close the cursor\n",
    "cursor.close()\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df_slots_aims = pd.DataFrame(slots_aims, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slots_aims.to_csv(\"df__slots_aims.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the AIMS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Flights (F) table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      aircraftregistration        date  total_flight_hours  \\\n",
      "0                   XY-AAB  2023-01-01                 8.0   \n",
      "1                   XY-AAB  2023-01-03                 0.0   \n",
      "2                   XY-AAB  2023-01-04                 1.0   \n",
      "3                   XY-AAB  2023-01-06                 9.0   \n",
      "4                   XY-AAB  2023-01-08                 4.0   \n",
      "...                    ...         ...                 ...   \n",
      "82355               XY-ZZE  2023-12-24                 4.0   \n",
      "82356               XY-ZZE  2023-12-25                 6.0   \n",
      "82357               XY-ZZE  2023-12-26                 2.0   \n",
      "82358               XY-ZZE  2023-12-27                 6.0   \n",
      "82359               XY-ZZE  2023-12-28                 5.0   \n",
      "\n",
      "       total_flight_cycles  \n",
      "0                        2  \n",
      "1                        1  \n",
      "2                        1  \n",
      "3                        2  \n",
      "4                        1  \n",
      "...                    ...  \n",
      "82355                    2  \n",
      "82356                    2  \n",
      "82357                    2  \n",
      "82358                    2  \n",
      "82359                    2  \n",
      "\n",
      "[82360 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#R1 requirements calculation\n",
    "\n",
    "df = df_flights.copy()\n",
    "\n",
    "# Ensure 'actualdeparture' and 'actualarrival' are in datetime format\n",
    "df['actualdeparture'] = pd.to_datetime(df['actualdeparture'], errors='coerce')\n",
    "df['actualarrival'] = pd.to_datetime(df['actualarrival'], errors='coerce')\n",
    "\n",
    "# Filter out only non-cancelled flights\n",
    "df_valid_flights = df[df['cancelled'] == False].copy()\n",
    "\n",
    "# Drop rows with NaT in 'actualdeparture' or 'actualarrival'\n",
    "df_valid_flights = df_valid_flights.dropna(subset=['actualdeparture', 'actualarrival'])\n",
    "\n",
    "# Calculate flight duration in hours\n",
    "df_valid_flights['flight_duration_hours'] = (\n",
    "    (df_valid_flights['actualarrival'] - df_valid_flights['actualdeparture']).dt.total_seconds() / 3600\n",
    ")\n",
    "\n",
    "# Ensure 'scheduleddeparture' is treated as a date column\n",
    "df_valid_flights['scheduleddeparture_date'] = pd.to_datetime(\n",
    "    df_valid_flights['scheduleddeparture'], errors='coerce'\n",
    ").dt.date\n",
    "\n",
    "# Group by 'aircraftregistration' and 'scheduleddeparture_date' to calculate total flight hours and cycles\n",
    "total_flight_summary = (\n",
    "    df_valid_flights\n",
    "    .groupby(['aircraftregistration', 'scheduleddeparture_date'])\n",
    "    .agg(\n",
    "        total_flight_hours=('flight_duration_hours', 'sum'),  # Sum flight hours\n",
    "        total_flight_cycles=('flight_duration_hours', 'count')  # Count valid flights (cycles)\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "total_flight_summary.columns = ['aircraftregistration', 'date', 'total_flight_hours', 'total_flight_cycles']\n",
    "\n",
    "# Display the result\n",
    "print(total_flight_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flights-F data:\n",
    "total_flight_summary.to_csv('total_flight_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Flight Issues (F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date aircraftregistration  delay_rate  cancellation_rate\n",
      "0     2023-01               XY-AAB    0.045455           0.022222\n",
      "1     2023-01               XY-ACY    0.071429           0.142857\n",
      "2     2023-01               XY-AFD    0.027027           0.026316\n",
      "3     2023-01               XY-AGF    0.073171           0.046512\n",
      "4     2023-01               XY-ALX    0.127660           0.078431\n",
      "...       ...                  ...         ...                ...\n",
      "3391  2023-12               XY-ZKT    0.160714           0.081967\n",
      "3392  2023-12               XY-ZPA    0.142857           0.023256\n",
      "3393  2023-12               XY-ZUS    0.085714           0.027778\n",
      "3394  2023-12               XY-ZWY    0.142857           0.092593\n",
      "3395  2023-12               XY-ZZE    0.048780           0.023810\n",
      "\n",
      "[3396 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df_flights.copy()\n",
    "\n",
    "# Convert 'scheduleddeparture' to a datetime format and extract month and year\n",
    "df['scheduleddeparture'] = pd.to_datetime(df['scheduleddeparture'], errors='coerce', format='%H:%M.%S')\n",
    "df['year_month'] = pd.to_datetime(df['scheduleddeparture']).dt.to_period('M')\n",
    "\n",
    "# Handle NaN or invalid 'scheduleddeparture' by removing rows without valid dates\n",
    "df = df.dropna(subset=['year_month'])\n",
    "\n",
    "# Grouping the data by 'year_month' and 'aircraftregistration'\n",
    "summary = df.groupby(['year_month', 'aircraftregistration']).agg(\n",
    "    total_flights=('id', 'count'),\n",
    "    cancelled_flights=('cancelled', lambda x: (x == True).sum()),\n",
    "    non_cancelled_flights=('cancelled', lambda x: (x == False).sum()),\n",
    "    delayed_flights=('delaycode', lambda x: x.notna().sum())\n",
    ").reset_index()\n",
    "\n",
    "# Calculating delay_rate and cancellation_rate\n",
    "summary['delay_rate'] = summary['delayed_flights'] / summary['non_cancelled_flights']\n",
    "summary['cancellation_rate'] = summary['cancelled_flights'] / summary['total_flights']\n",
    "\n",
    "# Final DataFrame: flight_issues\n",
    "flight_issues = summary[['year_month', 'aircraftregistration', 'delay_rate', 'cancellation_rate']]\n",
    "flight_issues = flight_issues.rename(columns={'year_month': 'date'})\n",
    "\n",
    "# Display the result\n",
    "print(flight_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_issues.to_csv(\"flight_issues.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THQDMkuKsmKg"
   },
   "source": [
    "## Extracting the AMOS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "K_vzjThMeATB",
    "outputId": "fd3a437d-86f0-4883-e162-932c0d05ee14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_24844\\297954291.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_maintenance_amos = sqlio.read_sql_query(Q2, amos)\n"
     ]
    }
   ],
   "source": [
    "## Maintenance Events\n",
    "Q2 = \"SELECT * FROM MaintenanceEvents\"\n",
    "\n",
    "df_maintenance_amos = sqlio.read_sql_query(Q2, amos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maintenance_amos.to_csv(\"df_maintenance_amos.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_24844\\846797191.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_OI_amos = sqlio.read_sql_query(Q3, amos)\n"
     ]
    }
   ],
   "source": [
    "## Operational interruption\n",
    "\n",
    "Q3 = \"SELECT * FROM OperationInterruption\"\n",
    "\n",
    "df_OI_amos = sqlio.read_sql_query(Q3, amos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OI_amos.to_csv(\"df_OI_amos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_24844\\513330461.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_Work_Orders_amos = sqlio.read_sql_query(Q4, amos)\n"
     ]
    }
   ],
   "source": [
    "## Work Orders\n",
    "\n",
    "Q4 = \"SELECT * FROM WorkOrders\"\n",
    "df_Work_Orders_amos = sqlio.read_sql_query(Q4, amos)\n",
    "\n",
    "df_Work_Orders_amos.to_csv(\"df_Work_Orders_amos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forecasted Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Technical log book orders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw6ovXWF7nrT"
   },
   "source": [
    "## Loading data into a Database table\n",
    "\n",
    "Lastly, we can load the resulting data frame into a database table.\n",
    "\n",
    "More info on inporting data to  DuckDB from Pandas:\n",
    "https://duckdb.org/docs/guides/python/import_pandas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "i6gfZ3uj54k2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workorderid</th>\n",
       "      <th>aircraftregistration</th>\n",
       "      <th>executiondate</th>\n",
       "      <th>executionplace</th>\n",
       "      <th>workpackage</th>\n",
       "      <th>kind</th>\n",
       "      <th>aircraft_reg_code</th>\n",
       "      <th>manufacturer_serial_number</th>\n",
       "      <th>aircraft_model</th>\n",
       "      <th>aircraft_manufacturer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [workorderid, aircraftregistration, executiondate, executionplace, workpackage, kind, aircraft_reg_code, manufacturer_serial_number, aircraft_model, aircraft_manufacturer]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first store the schema and content of our dataframe into a temp DB table.\n",
    "outputDB.execute(\"CREATE TABLE IF NOT EXISTS temp AS SELECT * FROM dfFiltered\")\n",
    "\n",
    "\n",
    "# We can then read the stored DB table into a new data frame and print its content\n",
    "outputDB.execute(\"select * from temp\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJss_G7M7nrc"
   },
   "source": [
    "###Finalize work\n",
    "\n",
    "Once you finish working with the notebook, please execute the code below to close the connection with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "p7gx-gxi7nrc",
    "outputId": "a51b6b69-debb-4660-c590-ee2dd2ee9d3d"
   },
   "outputs": [],
   "source": [
    "aims.close()\n",
    "amos.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
